import streamlit as st
from PIL import Image
import json
import torch
import torch.nn as nn
from torchvision import io
from torchvision import transforms as T
from torchvision.models import resnet50, ResNet50_Weights
from torch.nn import functional as F
import requests
from io import BytesIO
import time
import numpy as np

device = torch.device('cpu')
model = resnet50(weights=ResNet50_Weights.DEFAULT)
model.fc = nn.Linear(2048, 6)
model.load_state_dict(torch.load('model_multiclass_cpu.pt', map_location=device))
model.to(device)

class_translation = {
    "buildings": "–ó–¥–∞–Ω–∏—è",
    "forest": "–õ–µ—Å",
    "glacier": "–õ–µ–¥–Ω–∏–∫",
    "mountain": "–ì–æ—Ä–∞",
    "sea": "–ú–æ—Ä–µ",
    "street": "–£–ª–∏—Ü–∞",
}
idx2class= {0: 'buildings',
                1: 'forest',
                2: 'glacier',
                3: 'mountain',
                4: 'sea',
                5: 'street'}

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è 
def get_prediction(image):
    transform = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
    ])
    
    image = transform(image).unsqueeze(0).to(device)
    
    start_time = time.time() # –°—Ç–∞—Ä—Ç –æ—Ç—Å—á–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ 
    model.to(device)
    model.eval()

    with torch.no_grad():
        output = model(image)  
        pred_class = torch.argmax(output).round().item() 
        probability = np.round(torch.softmax(output, dim=1)[0, pred_class].item() * 100, 2)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        probabilities = torch.softmax(output, dim=1)[0].tolist()
        class_probabilities = [
        f"{class_translation[idx2class[i]]}: {prob*100:.2f}%" for i, prob in enumerate(probabilities)]

        class_result = f"–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {probability}%: **{class_translation[idx2class[pred_class]]}**" # –ö–ª–∞—Å—Å, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –º–æ–¥–µ–ª—å—é
        overall_result = f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤: " + ", ".join(class_probabilities) # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–∂–µ–Ω–æ—Å—Ç–∏ –∫–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º
    
    end_time = time.time() # –ö–æ–Ω–µ—Ü –æ—Ç—Å—á–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ 
    elapsed_time = end_time - start_time # –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ 

    return class_result, elapsed_time, overall_result  # f"–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ : {class_translation[idx2class[pred_class]]}"

st.write("## Intel Image Classification üèûÔ∏è")
st.sidebar.write("Choose application above")
st.markdown(
        """
        –≠—Ç–æ—Ç streamlit-—Å–µ—Ä–≤–∏—Å –ø–æ–∑–≤–æ–ª–∏—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ
    """
)
button_style = """
    <style>
    .center-align {
        display: flex;
        justify-content: center;
    }
    </style>
    """
image_source = st.radio("Choose the option of uploading the image:", ("File", "URL"))  # –ú–µ–Ω—é –≤—ã–±–æ—Ä–∞ —Ç–æ–≥–æ –∫–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É: –ø–æ —Å—Å—ã–ª–∫–µ –∏–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞

try:
    if image_source == "File":
        uploaded_files = st.file_uploader("Upload the image", type=["jpg", "png", "jpeg"], accept_multiple_files=True) 
        if uploaded_files:
            for uploaded_file in uploaded_files:
                image = Image.open(uploaded_file)
                st.image(image, caption="Uploaded image", use_column_width=True)
                if st.button(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å –¥–ª—è {uploaded_file.name}"):
                    predicted_class, elapsed_time, overall_result = get_prediction(image)
                    st.success(predicted_class)
                    st.success(overall_result)
                    st.info(f"–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏: {elapsed_time:.4f} —Å–µ–∫—É–Ω–¥")
    else:
        url = st.text_input("Enter the URL of image...")
        if url:
            response = requests.get(url)
            if response.status_code == 200:
                image = Image.open(BytesIO(response.content))
                st.image(image, caption="Uploaded image", use_column_width=True)
                if st.button(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å"):
                    predicted_class, elapsed_time, overall_result = get_prediction(image)
                    st.success(predicted_class)
                    st.success(overall_result)
                    st.info(f"–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏: {elapsed_time:.4f} —Å–µ–∫—É–Ω–¥")
            else:
                st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–≤–µ–¥–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞.")
except Exception as e:
    st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {str(e)}")
st.markdown(button_style, unsafe_allow_html=True)  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª—å –∫ –∫–Ω–æ–ø–∫–µ
